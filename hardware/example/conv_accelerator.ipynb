{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu does convolution in 7.585 seconds\n",
      "programmable logic does convolution in in 0.035 seconds\n",
      "PL is up to 213.72 times faster than snickerdoodle cpu execution\n",
      "Difference between cpu and pl results should be zero: 0\n"
     ]
    }
   ],
   "source": [
    "#use a pynq overlay to compute a 1-D convolution.  The overlay convolves any filter of length 1 to 255\n",
    "#to substrate data of any length.  This is beyond what the hw question asked for; I pushed the problem\n",
    "#scope just so I could show a maximum speed advantage over CPU execution. \n",
    "\n",
    "import numpy as np\n",
    "import pynq\n",
    "import time\n",
    "\n",
    "\n",
    "overlay = pynq.Overlay(\"conv1D.bit\")\n",
    "dma_toPL = overlay.axi_dma_from_ps_to_pl\n",
    "dma_fromPL = overlay.axi_dma_from_pl_to_ps\n",
    "\n",
    "#generate random data\n",
    "n1 = 5000000 #process 5 million random numbers\n",
    "data1 = np.random.randint(low=0, high=2**12, size=[n1], dtype=np.uint16) #conv substrate\n",
    "n2 = 255\n",
    "data2 = np.random.randint(low=0, high=2**12, size=[n2], dtype=np.uint16) #conv filter\n",
    "    \n",
    "#set up PYNQ data arrays (can be used as numpy arrays, but include physical memory addresses for DMA access)\n",
    "pynq_data1 = pynq.allocate(shape=(n1,), dtype=np.uint16)\n",
    "pynq_data2 = pynq.allocate(shape=(n2,), dtype=np.uint16)\n",
    "pynq_res = pynq.allocate(shape=(n1+n2-1), dtype=np.uint16)\n",
    "np.copyto(pynq_data1, data1)#copy numpy-generated data to pynq arrays\n",
    "np.copyto(pynq_data2, data2)\n",
    "data2 = np.flip(data2, axis=0)#overlay convolution does not flip filter - instead, flip numpy filter for cpu convolve\n",
    "\n",
    "#see how long it takes CPU processing to do operation\n",
    "start_time = time.time()\n",
    "cpu_res = np.convolve(data1, data2)\n",
    "cputime = time.time() - start_time\n",
    "print(\"cpu does convolution in %.3f seconds\"%cputime)\n",
    "\n",
    "#execute and time operation in programmable logic\n",
    "start_time = time.time()\n",
    "\n",
    "#send filter: overlay is designed to first recieve the relatively short filter, then recive relatively long data\n",
    "dma_toPL.sendchannel.transfer(pynq_data2)\n",
    "dma_toPL.sendchannel.wait()\n",
    "\n",
    "#send data and start waiting for results:\n",
    "dma_toPL.sendchannel.transfer(pynq_data1)\n",
    "dma_fromPL.recvchannel.transfer(pynq_res)\n",
    "dma_toPL.sendchannel.wait()\n",
    "dma_fromPL.recvchannel.wait()\n",
    "pltime = time.time()-start_time\n",
    "print(\"programmable logic does convolution in in %.3f seconds\"%pltime)\n",
    "print(\"PL is up to %.2f times faster than snickerdoodle cpu execution\"%(cputime/pltime))\n",
    "print(\"Difference between cpu and pl results should be zero: %i\" % np.sum(pynq_res-cpu_res))\n",
    "\n",
    "# print(\"\\n\\nvisual inspection of numpy filter:\")\n",
    "# print(data2)\n",
    "# print(\"visual inspection of pynq filter:\")\n",
    "# print(pynq_data2)\n",
    "# print(\"visual inspection of source data:\")\n",
    "# print(data1[0:25])\n",
    "# print(\"visual inspection of numpy result:\")\n",
    "# print(cpu_res[0:15])\n",
    "# print(\"visual inspection of pl result:\")\n",
    "# print(pynq_res[0:15])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
